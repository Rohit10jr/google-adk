{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e559a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Turn 1: Capturing Information ---\n",
      "Agent 1 Response: Understood. You like Project Alpha.\n",
      "\n",
      "\n",
      "--- Adding Session 1 to Memory ---\n",
      "Session added to memory.\n",
      "\n",
      "--- Turn 2: Recalling Information ---\n",
      "Running MemoryRecallAgent...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Event: MemoryRecallAgent - Type: FuncCall\n",
      "  Event: MemoryRecallAgent - Type: FuncResp\n",
      "  Event: MemoryRecallAgent - Type: Text\n",
      "Agent 2 Final Response: Your favorite project is Project Alpha.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.sessions import InMemorySessionService, Session\n",
    "from google.adk.memory import InMemoryMemoryService # Import MemoryService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.tools import load_memory # Tool to query memory\n",
    "from google.genai.types import Content, Part\n",
    "\n",
    "# --- Constants ---\n",
    "APP_NAME = \"memory_example_app\"\n",
    "USER_ID = \"mem_user\"\n",
    "MODEL = \"gemini-2.0-flash\" # Use a valid model\n",
    "\n",
    "# --- Agent Definitions ---\n",
    "# Agent 1: Simple agent to capture information\n",
    "info_capture_agent = LlmAgent(\n",
    "    model=MODEL,\n",
    "    name=\"InfoCaptureAgent\",\n",
    "    instruction=\"Acknowledge the user's statement.\",\n",
    "    # output_key=\"captured_info\" # Could optionally save to state too\n",
    ")\n",
    "\n",
    "# Agent 2: Agent that can use memory\n",
    "memory_recall_agent = LlmAgent(\n",
    "    model=MODEL,\n",
    "    name=\"MemoryRecallAgent\",\n",
    "    instruction=\"Answer the user's question. Use the 'load_memory' tool \"\n",
    "                \"if the answer might be in past conversations.\",\n",
    "    tools=[load_memory] # Give the agent the tool\n",
    ")\n",
    "\n",
    "# --- Services and Runner ---\n",
    "session_service = InMemorySessionService()\n",
    "memory_service = InMemoryMemoryService() # Use in-memory for demo\n",
    "\n",
    "runner = Runner(\n",
    "    # Start with the info capture agent\n",
    "    agent=info_capture_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service # Provide the memory service to the Runner\n",
    ")\n",
    "\n",
    "# --- Scenario ---\n",
    "\n",
    "# Turn 1: Capture some information in a session\n",
    "print(\"--- Turn 1: Capturing Information ---\")\n",
    "session1_id = \"session_info\"\n",
    "session1 = await runner.session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=session1_id)\n",
    "user_input1 = Content(parts=[Part(text=\"My favorite project is Project Alpha.\")], role=\"user\")\n",
    "\n",
    "# Run the agent\n",
    "final_response_text = \"(No final response)\"\n",
    "async for event in runner.run_async(user_id=USER_ID, session_id=session1_id, new_message=user_input1):\n",
    "    if event.is_final_response() and event.content and event.content.parts:\n",
    "        final_response_text = event.content.parts[0].text\n",
    "print(f\"Agent 1 Response: {final_response_text}\")\n",
    "\n",
    "# Get the completed session\n",
    "completed_session1 = await runner.session_service.get_session(app_name=APP_NAME, user_id=USER_ID, session_id=session1_id)\n",
    "\n",
    "# Add this session's content to the Memory Service\n",
    "print(\"\\n--- Adding Session 1 to Memory ---\")\n",
    "memory_service = await memory_service.add_session_to_memory(completed_session1)\n",
    "print(\"Session added to memory.\")\n",
    "\n",
    "# Turn 2: In a *new* (or same) session, ask a question requiring memory\n",
    "print(\"\\n--- Turn 2: Recalling Information ---\")\n",
    "session2_id = \"session_recall\" # Can be same or different session ID\n",
    "session2 = await runner.session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=session2_id)\n",
    "\n",
    "# Switch runner to the recall agent\n",
    "runner.agent = memory_recall_agent\n",
    "user_input2 = Content(parts=[Part(text=\"What is my favorite project?\")], role=\"user\")\n",
    "\n",
    "# Run the recall agent\n",
    "print(\"Running MemoryRecallAgent...\")\n",
    "final_response_text_2 = \"(No final response)\"\n",
    "async for event in runner.run_async(user_id=USER_ID, session_id=session2_id, new_message=user_input2):\n",
    "    print(f\"  Event: {event.author} - Type: {'Text' if event.content and event.content.parts and event.content.parts[0].text else ''}\"\n",
    "        f\"{'FuncCall' if event.get_function_calls() else ''}\"\n",
    "        f\"{'FuncResp' if event.get_function_responses() else ''}\")\n",
    "    if event.is_final_response() and event.content and event.content.parts:\n",
    "        final_response_text_2 = event.content.parts[0].text\n",
    "        print(f\"Agent 2 Final Response: {final_response_text_2}\")\n",
    "        break # Stop after final response\n",
    "\n",
    "# Expected Event Sequence for Turn 2:\n",
    "# 1. User sends \"What is my favorite project?\"\n",
    "# 2. Agent (LLM) decides to call `load_memory` tool with a query like \"favorite project\".\n",
    "# 3. Runner executes the `load_memory` tool, which calls `memory_service.search_memory`.\n",
    "# 4. `InMemoryMemoryService` finds the relevant text (\"My favorite project is Project Alpha.\") from session1.\n",
    "# 5. Tool returns this text in a FunctionResponse event.\n",
    "# 6. Agent (LLM) receives the function response, processes the retrieved text.\n",
    "# 7. Agent generates the final answer (e.g., \"Your favorite project is Project Alpha.\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
